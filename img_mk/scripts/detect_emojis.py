import cv2
import torch
from torchvision import transforms, models
from PIL import Image
import os

# YOLOv5 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
yolo_model = torch.hub.load('ultralytics/yolov5', 'custom', path="D:\\git\\img_mk\\models\\yolov5\\best.pt")

# ê°ì • ë¶„ë¥˜ ëª¨ë¸ ì •ì˜ ë° ìƒíƒœ ì‚¬ì „ ë¡œë“œ
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# InceptionV3 ê¸°ë°˜ì˜ ëª¨ë¸ ì •ì˜
emotion_model = models.inception_v3(pretrained=False)
emotion_model.fc = torch.nn.Sequential(
    torch.nn.Linear(emotion_model.fc.in_features, 256),
    torch.nn.ReLU(),
    torch.nn.Dropout(0.5),
    torch.nn.Linear(256, 7),  # ê°ì • í´ë˜ìŠ¤ ê°œìˆ˜ (ì˜ˆì‹œë¡œ 7ê°œ í´ë˜ìŠ¤ ì‚¬ìš©)
    torch.nn.LogSoftmax(dim=1)
)
emotion_model.load_state_dict(torch.load("D:\\git\\img_mk\\models\\emotion_model.pth"))
emotion_model = emotion_model.to(device)
emotion_model.eval()

# ì´ëª¨ì§€ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
emotion_to_emoji = {
    'angry': 'ğŸ˜ ',
    'anxiety': 'ğŸ˜°',
    'happy': 'ğŸ˜Š',
    'neutrality': 'ğŸ˜',
    'panic': 'ğŸ˜±',
    'sad': 'ğŸ˜¢',
    'wound': 'ğŸ¤•'
}

# ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
image_folder = 'D:/kor_face_ai/real_t'

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((299, 299)),  # InceptionV3 ì…ë ¥ í¬ê¸°ì— ë§ì¶° ì¡°ì •
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜
def process_image(image_path, output_path):
    # ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
    img = cv2.imread(image_path)
    results = yolo_model(img)

    # ë°”ìš´ë”© ë°•ìŠ¤ ì–»ê¸°
    for det in results.xyxy[0]:
        x1, y1, x2, y2, conf, cls = map(int, det)
        face_img = img[y1:y2, x1:x2]

        # ì–¼êµ´ ì´ë¯¸ì§€ PIL í˜•ì‹ìœ¼ë¡œ ë³€í™˜ í›„ ê°ì • ì˜ˆì¸¡
        face_pil = Image.fromarray(cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB))
        face_tensor = transform(face_pil).unsqueeze(0).to(device)
        emotion_output = emotion_model(face_tensor)
        _, predicted = torch.max(emotion_output, 1)
        emotion_label = predicted.item()

        # ê°ì • ë ˆì´ë¸”ì— ë”°ë¥¸ ì´ëª¨ì§€ ì„ íƒ
        emotion = list(emotion_to_emoji.keys())[emotion_label]
        emoji = emotion_to_emoji[emotion]

        # ì´ë¯¸ì§€ì— ì´ëª¨ì§€ ë§¤í•‘
        cv2.putText(img, emoji, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)

    # ê²°ê³¼ ì €ì¥
    cv2.imwrite(output_path, img)

# ì‚¬ìš©ì ì •ì˜ ê²°ê³¼ ì €ì¥ ê²½ë¡œ ì…ë ¥ (ê¸°ë³¸ ê²½ë¡œ ì§€ì • ê°€ëŠ¥)
output_folder = input("D:\\git\\img_mk\\results\\output_images")
if not output_folder:
    output_folder = "D:\\git\\img_mk\\results\\output_images"

# ì´ë¯¸ì§€ í´ë” ë‚´ ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬
if not os.path.exists(output_folder):
    os.makedirs(output_folder)

for image_file in os.listdir(image_folder):
    image_path = os.path.join(image_folder, image_file)
    output_path = os.path.join(output_folder, os.path.basename(image_path))
    process_image(image_path, output_path)
